# AI Usage Analytics Data Dictionary
*Comprehensive Technical Documentation for Samba AI Usage Analytics Platform*

**Generated by Winston (Architect)** | **Date:** 2025-09-27 | **Version:** 1.0

---

## Executive Summary

This data dictionary provides detailed documentation for a sophisticated AI usage analytics platform that tracks, measures, and analyzes usage across multiple AI platforms including **Cursor** (coding assistant) and **Anthropic Claude** (via Claude Code, Claude API, and Claude Web). The system implements a comprehensive dimensional data model with star schema design, tracking cost allocation, productivity metrics, and ROI analysis for engineering teams.

### Platform Distinction Strategy
The system differentiates between:
- **Cursor**: Direct coding assistant usage with email-based attribution
- **Claude Code**: Anthropic's IDE integration (identified via workspace ID: `wrkspc_01WtfAtqQsV3zBDs9RYpNZdR`)
- **Claude API**: Direct API usage by developers
- **Claude Web**: Web interface usage (planned)

---

## Data Architecture Overview

```
Raw Data Layer (APIs) → Dimension Tables → Fact Tables → Business Views
     ↓                      ↓               ↓           ↓
   ETL/ELT              Attribution      Analytics   Dashboards
```

### Data Flow Pipeline
1. **Ingestion**: Daily API calls to Cursor and Anthropic APIs
2. **Attribution**: User mapping via Google Sheets + API key mappings
3. **Transformation**: Raw data → normalized fact/dimension tables
4. **Aggregation**: Business metrics via SQL views
5. **Visualization**: Looker Studio dashboards + web app

---

## Table Inventory & Relationships

### Raw Data Tables (Landing Zone)

#### `raw_cursor_usage`
**Purpose**: Stores raw usage data from Cursor Admin API
**Partitioning**: By `ingest_date` (daily)
**Clustering**: By `email`, `usage_date`

| Column | Type | Description | Business Rules |
|--------|------|-------------|----------------|
| `email` | STRING | User email from Cursor API | NOT NULL, primary identifier |
| `usage_date` | DATE | Date of usage activity | NOT NULL |
| `total_lines_added` | INT64 | Total lines of code suggested | Default: 0 |
| `accepted_lines_added` | INT64 | Lines of code accepted by user | Default: 0, ≤ total_lines_added |
| `total_accepts` | INT64 | Number of suggestion acceptances | Default: 0 |
| `subscription_included_reqs` | INT64 | Requests covered by subscription | Default: 0 |
| `usage_based_reqs` | INT64 | Additional paid requests | Default: 0 |
| `ingest_date` | DATE | Date record was ingested | NOT NULL |
| `ingest_timestamp` | TIMESTAMP | Exact ingestion time | Auto-generated |
| `request_id` | STRING | Pipeline execution tracking ID | UUID format |
| `raw_response` | JSON | Complete API response for debugging | Unstructured |

**Key Metrics Calculated**:
- **Acceptance Rate**: `accepted_lines_added / total_lines_added`
- **Request Efficiency**: `total_accepts / (subscription_included_reqs + usage_based_reqs)`

#### `raw_anthropic_usage`
**Purpose**: Stores token usage data from Anthropic Admin API
**Partitioning**: By `ingest_date`
**Clustering**: By `api_key_id`, `model`, `usage_date`

| Column | Type | Description | Business Rules |
|--------|------|-------------|----------------|
| `api_key_id` | STRING | Anthropic API key identifier | NOT NULL |
| `workspace_id` | STRING | Workspace identifier (Claude Code detection) | Nullable |
| `model` | STRING | AI model used (claude-3-5-sonnet, etc.) | Nullable |
| `uncached_input_tokens` | INT64 | Input tokens not from cache | Default: 0 |
| `cached_input_tokens` | INT64 | Input tokens served from cache | Default: 0 |
| `cache_read_input_tokens` | INT64 | Tokens read from cache | Default: 0 |
| `output_tokens` | INT64 | Generated output tokens | Default: 0 |
| `usage_date` | DATE | Date of usage | NOT NULL |
| `usage_hour` | INT64 | Hour of usage (0-23) | Nullable |
| `ingest_date` | DATE | Date record was ingested | NOT NULL |
| `ingest_timestamp` | TIMESTAMP | Exact ingestion time | Auto-generated |
| `request_id` | STRING | Pipeline execution tracking ID | UUID format |
| `raw_response` | JSON | Complete API response | Unstructured |

**Platform Detection Logic**:
- If `workspace_id = 'wrkspc_01WtfAtqQsV3zBDs9RYpNZdR'` → `claude_code`
- If `api_key_id` in platform mapping → use mapping value
- Default → `claude_api`

#### `raw_anthropic_cost`
**Purpose**: Stores cost data from Anthropic billing API
**Partitioning**: By `ingest_date`
**Clustering**: By `api_key_id`, `model`, `cost_date`

| Column | Type | Description | Business Rules |
|--------|------|-------------|----------------|
| `api_key_id` | STRING | API key identifier | NOT NULL |
| `workspace_id` | STRING | Workspace identifier | Nullable |
| `model` | STRING | AI model used | Nullable |
| `cost_usd` | FLOAT64 | Cost in USD | Default: 0.0, ≥ 0 |
| `cost_type` | STRING | Type of cost charge | 'input_tokens', 'output_tokens', 'cache_read' |
| `cost_date` | DATE | Date cost was incurred | NOT NULL |
| `cost_hour` | INT64 | Hour of cost (0-23) | Nullable |
| `ingest_date` | DATE | Date record was ingested | NOT NULL |
| `ingest_timestamp` | TIMESTAMP | Exact ingestion time | Auto-generated |
| `request_id` | STRING | Pipeline execution tracking ID | UUID format |
| `raw_response` | JSON | Complete API response | Unstructured |

---

### Dimension Tables (Master Data)

#### `dim_users`
**Purpose**: User master data for cost allocation and analytics
**Clustering**: By `email`, `department`

| Column | Type | Description | Business Rules |
|--------|------|-------------|----------------|
| `user_id` | STRING | Unique user identifier | Primary key |
| `email` | STRING | User email address | NOT NULL, unique |
| `first_name` | STRING | User first name | Nullable |
| `last_name` | STRING | User last name | Nullable |
| `display_name` | STRING | Display name for UI | Nullable |
| `department` | STRING | Department/team assignment | For cost allocation |
| `team` | STRING | Specific team within department | Nullable |
| `manager_email` | STRING | Manager's email for hierarchy | Nullable |
| `is_active` | BOOLEAN | Active user flag | Default: true |
| `created_date` | DATE | User creation date | Nullable |
| `updated_date` | DATE | Last update date | Default: CURRENT_DATE() |
| `created_by` | STRING | Created by system/user | Default: 'system' |
| `updated_by` | STRING | Updated by system/user | Default: 'system' |
| `updated_timestamp` | TIMESTAMP | Last update timestamp | Auto-updated |

#### `dim_api_keys`
**Purpose**: API key to user attribution mapping (sourced from Google Sheets)
**Clustering**: By `platform`, `user_email`, `api_key_id`

| Column | Type | Description | Business Rules |
|--------|------|-------------|----------------|
| `api_key_id` | STRING | API key identifier | Primary key |
| `api_key_name` | STRING | Human-readable key name | Nullable |
| `user_email` | STRING | Associated user email | NOT NULL |
| `user_id` | STRING | Associated user ID | Nullable |
| `platform` | STRING | Platform type | 'anthropic', 'cursor', 'claude_api', 'claude_code' |
| `workspace_id` | STRING | Associated workspace | Nullable |
| `purpose` | STRING | Key purpose/environment | 'development', 'production', 'testing' |
| `is_active` | BOOLEAN | Active key flag | Default: true |
| `created_date` | DATE | Key creation date | Nullable |
| `expires_date` | DATE | Key expiration date | Nullable |
| `notes` | STRING | Additional notes | Nullable |
| `updated_date` | DATE | Last update date | Default: CURRENT_DATE() |
| `updated_timestamp` | TIMESTAMP | Last update timestamp | Auto-updated |
| `created_by` | STRING | Created by system | Default: 'google_sheets_import' |
| `updated_by` | STRING | Updated by system | Default: 'google_sheets_import' |

---

### Fact Tables (Metrics/Measurements)

#### `fct_usage_daily`
**Purpose**: Normalized daily usage facts across all platforms
**Partitioning**: By `usage_date` (daily)
**Clustering**: By `platform`, `user_email`, `model`

| Column | Type | Description | Calculation Method |
|--------|------|-------------|-------------------|
| `usage_date` | DATE | Date of usage | Direct from source |
| `platform` | STRING | Platform identifier | Normalized: 'cursor', 'claude_api', 'claude_code', 'claude_web' |
| `user_email` | STRING | Attributed user email | Via attribution engine |
| `user_id` | STRING | User identifier | From dim_users join |
| `api_key_id` | STRING | API key used | Direct from source |
| `model` | STRING | AI model used | Direct from source |
| `workspace_id` | STRING | Workspace context | Direct from source |
| `input_tokens` | INT64 | Input tokens used | Anthropic: uncached_input_tokens |
| `output_tokens` | INT64 | Output tokens generated | Direct from source |
| `cached_input_tokens` | INT64 | Cached input tokens | Anthropic only |
| `cache_read_tokens` | INT64 | Cache read tokens | Anthropic only |
| `sessions` | INT64 | Number of sessions | Cursor: session_count, Anthropic: derived |
| `lines_of_code_added` | INT64 | LOC suggested | Cursor: total_lines_added |
| `lines_of_code_accepted` | INT64 | LOC accepted | Cursor: accepted_lines_added |
| `acceptance_rate` | FLOAT64 | **Calculated**: `lines_of_code_accepted / NULLIF(lines_of_code_added, 0)` | Range: 0.0-1.0 |
| `total_accepts` | INT64 | Number of accepts | Cursor: total_accepts |
| `subscription_requests` | INT64 | Subscription-covered requests | Cursor: subscription_included_reqs |
| `usage_based_requests` | INT64 | Usage-based requests | Cursor: usage_based_reqs |
| `ingest_date` | DATE | Data ingestion date | Pipeline metadata |
| `created_timestamp` | TIMESTAMP | Record creation time | Auto-generated |
| `request_id` | STRING | Pipeline execution ID | Traceability |

**Key Business Metrics**:
- **Productivity Score**: `lines_of_code_accepted / sessions`
- **Efficiency Ratio**: `lines_of_code_accepted / (input_tokens + output_tokens)`
- **Token Utilization**: `(input_tokens + output_tokens) / sessions`

#### `fct_cost_daily`
**Purpose**: Daily cost facts for financial reporting and ROI analysis
**Partitioning**: By `cost_date` (daily)
**Clustering**: By `platform`, `user_email`, `model`

| Column | Type | Description | Calculation Method |
|--------|------|-------------|-------------------|
| `cost_date` | DATE | Date cost was incurred | Direct from source |
| `platform` | STRING | Platform identifier | Normalized platform values |
| `user_email` | STRING | Attributed user email | Via attribution engine |
| `user_id` | STRING | User identifier | From dim_users join |
| `api_key_id` | STRING | API key used | Direct from source |
| `model` | STRING | AI model used | Direct from source |
| `workspace_id` | STRING | Workspace context | Direct from source |
| `cost_usd` | FLOAT64 | Cost in USD | Direct from billing API |
| `cost_type` | STRING | Type of cost | 'input_tokens', 'output_tokens', 'subscription', 'usage_based' |
| `volume_units` | INT64 | Units for cost calculation | tokens, requests, sessions |
| `unit_type` | STRING | Type of volume unit | 'tokens', 'requests', 'sessions' |
| `ingest_date` | DATE | Data ingestion date | Pipeline metadata |
| `created_timestamp` | TIMESTAMP | Record creation time | Auto-generated |
| `request_id` | STRING | Pipeline execution ID | Traceability |

**Key Cost Metrics**:
- **Cost Per Token**: `cost_usd / NULLIF(volume_units, 0)` (when unit_type = 'tokens')
- **Cost Per Session**: `cost_usd / NULLIF(volume_units, 0)` (when unit_type = 'sessions')
- **Daily Burn Rate**: `SUM(cost_usd)` by day
- **User Cost Allocation**: `SUM(cost_usd)` by user_email

---

## Business Intelligence Views

### `vw_productivity_metrics`
**Purpose**: Engineering productivity analytics with acceptance rates and trends
**Optimization**: Last 6 months data, partitioned queries

#### Key Metrics Calculated:

| Metric | Calculation | Business Meaning |
|--------|-------------|------------------|
| `daily_acceptance_rate` | `SUM(lines_of_code_accepted) / NULLIF(SUM(lines_of_code_added), 0)` | Daily coding efficiency |
| `lines_per_session` | `SUM(lines_of_code_accepted) / NULLIF(SUM(sessions), 0)` | Session productivity |
| `tokens_per_session` | `SUM(input_tokens + output_tokens) / NULLIF(SUM(sessions), 0)` | AI utilization per session |
| `efficiency_ratio` | `SUM(lines_of_code_accepted) / NULLIF(SUM(input_tokens + output_tokens), 0)` | Output efficiency |
| `mom_productivity_change_pct` | `(current_month_lines - prev_month_lines) / NULLIF(prev_month_lines, 0)` | Month-over-month growth |
| `monthly_engagement_rate` | `COUNT(DISTINCT usage_date) / days_in_month` | User engagement frequency |

#### Performance Tiers:
- **Top Performer**: ≥ 75th percentile acceptance rate
- **Above Average**: ≥ 50th percentile acceptance rate
- **Below Average**: ≥ 25th percentile acceptance rate
- **Needs Support**: < 25th percentile acceptance rate

#### Engagement Categories:
- **Highly Active**: ≥ 80% of days in month
- **Moderately Active**: ≥ 50% of days in month
- **Occasional**: ≥ 20% of days in month
- **Low Activity**: < 20% of days in month

### `vw_cost_allocation`
**Purpose**: ROI analysis and cost allocation for team/project reporting
**Optimization**: Last 12 months data with FULL OUTER JOIN for complete attribution

#### Key Metrics Calculated:

| Metric | Calculation | Business Meaning |
|--------|-------------|------------------|
| `cost_per_line_accepted` | `total_cost_usd / NULLIF(total_lines_accepted, 0)` | Cost efficiency per output |
| `cost_per_session` | `total_cost_usd / NULLIF(total_sessions, 0)` | Cost per usage session |
| `cost_per_1k_tokens` | `total_cost_usd / NULLIF(total_tokens, 0) * 1000` | Token cost efficiency |
| `estimated_roi_ratio` | `(total_lines_accepted * 50) / NULLIF(total_cost_usd, 0)` | ROI assuming $50/hour saved |

#### User Categories:
- **Power User**: ≥ 50 sessions/month
- **Regular User**: ≥ 20 sessions/month
- **Occasional User**: ≥ 5 sessions/month
- **Light User**: > 0 sessions/month
- **Cost Only**: Cost data but no usage data

#### Efficiency Tiers:
- **High Efficiency**: ≤ $0.10 per line accepted
- **Good Efficiency**: ≤ $0.25 per line accepted
- **Average Efficiency**: ≤ $0.50 per line accepted
- **Low Efficiency**: > $0.50 per line accepted

### `vw_executive_summary`
**Purpose**: High-level KPIs for executive dashboard
**Optimization**: Last 12 months with quarter-to-date and year-to-date calculations

#### Executive KPIs:

| KPI | Calculation | Target/Benchmark |
|-----|-------------|------------------|
| `total_monthly_cost` | `SUM(cost_usd)` by month | Budget vs. actual |
| `cost_per_active_user` | `total_monthly_cost / total_active_users` | Efficiency metric |
| `cost_growth_rate` | `(current_cost - prev_cost) / prev_cost` | Growth monitoring |
| `user_growth_rate` | `(current_users - prev_users) / prev_users` | Adoption tracking |
| `estimated_time_savings_ratio` | `(total_lines_accepted * 50) / total_monthly_cost` | ROI metric |
| `annual_run_rate` | `total_monthly_cost * 12` | Budget forecasting |

#### ROI Assessment Categories:
- **Excellent ROI**: ≤ $0.15 per line accepted
- **Good ROI**: ≤ $0.30 per line accepted
- **Acceptable ROI**: ≤ $0.50 per line accepted
- **Poor ROI**: > $0.50 per line accepted

#### Platform Preference Analysis:
- **Anthropic Heavy**: > 70% of cost from Anthropic platforms
- **Cursor Heavy**: > 70% of cost from Cursor
- **Balanced Usage**: No single platform dominance

### `vw_monthly_finance`
**Purpose**: Financial reporting optimized for Looker Studio
**Optimization**: Monthly aggregations with growth analysis

#### Financial Metrics:

| Metric | Calculation | Purpose |
|--------|-------------|---------|
| `platform_monthly_cost` | `SUM(cost_usd)` by platform/month | Platform cost tracking |
| `cost_per_user` | `platform_monthly_cost / unique_users` | User cost efficiency |
| `mom_cost_change_pct` | Month-over-month cost change | Growth analysis |
| `attribution_coverage` | `attributed_records / total_records` | Data quality metric |

#### Growth Categories:
- **High Growth**: > +20% MoM
- **Moderate Growth**: +5% to +20% MoM
- **Stable**: -5% to +5% MoM
- **Moderate Decline**: -20% to -5% MoM
- **Significant Decline**: < -20% MoM

#### Data Quality Status:
- **Excellent**: ≥ 95% attribution coverage
- **Good**: ≥ 85% attribution coverage
- **Acceptable**: ≥ 70% attribution coverage
- **Needs Attention**: < 70% attribution coverage

---

## Claude Code vs Cursor Integration Patterns

### Platform Differentiation Strategy

#### 1. **Cursor Integration**
- **Data Source**: Cursor Admin API (`/teams/daily-usage-data`)
- **Attribution Method**: Direct email from API response
- **Key Metrics**:
  - Lines of code (added/accepted)
  - Acceptance rates
  - Session counts
  - Request categorization (subscription vs. usage-based)
- **Cost Model**: Subscription + overage billing

#### 2. **Claude Code Integration**
- **Data Source**: Anthropic Admin API with workspace filtering
- **Attribution Method**: API key mapping via Google Sheets
- **Detection Logic**: `workspace_id = 'wrkspc_01WtfAtqQsV3zBDs9RYpNZdR'`
- **Key Metrics**:
  - Token usage (input/output/cached)
  - Model usage patterns
  - Workspace-level aggregation
- **Cost Model**: Token-based pricing

#### 3. **Claude API Integration**
- **Data Source**: Anthropic Admin API (non-Claude Code keys)
- **Attribution Method**: API key mapping via Google Sheets
- **Detection Logic**: Platform mapping lookup or default
- **Key Metrics**:
  - Token consumption
  - Model selection patterns
  - Direct API usage
- **Cost Model**: Token-based pricing

### Engineering Productivity Metrics

#### Combined Analysis Approach:
1. **Normalized Metrics**: Both platforms contribute to unified fact tables
2. **Platform-Specific Analysis**: Separate views for platform comparison
3. **Cross-Platform Users**: Users tracked across multiple platforms
4. **Unified ROI Calculation**: Combined cost and productivity analysis

#### Key Integration Points:
```sql
-- Example: Combined productivity calculation
SELECT
  user_email,
  SUM(CASE WHEN platform = 'cursor' THEN lines_of_code_accepted ELSE 0 END) as cursor_productivity,
  SUM(CASE WHEN platform = 'claude_code' THEN output_tokens ELSE 0 END) as claude_code_tokens,
  SUM(cost_usd) as total_ai_cost,
  -- Combined efficiency metric
  SAFE_DIVIDE(
    SUM(lines_of_code_accepted),
    SUM(cost_usd)
  ) as lines_per_dollar
FROM fct_usage_daily u
LEFT JOIN fct_cost_daily c USING (usage_date, user_email, platform)
GROUP BY user_email
```

---

## Data Quality Issues & Inconsistencies

### Identified Data Quality Challenges

#### 1. **Attribution Gaps**
- **Issue**: API keys without user mapping in Google Sheets
- **Impact**: ~5-15% of usage data marked as "unknown@unattributed.com"
- **Resolution**: Automated attribution alerts + manual mapping updates
- **Monitoring**: `vw_data_quality_dashboard` tracks attribution rates

#### 2. **Platform Detection Inconsistencies**
- **Issue**: API keys mapped to multiple platforms in different systems
- **Example**: Same API key appears as both "claude_api" and "claude_code"
- **Root Cause**: Platform mapping rules conflicts
- **Resolution**: Platform mapping priority hierarchy

#### 3. **Date Handling Variations**
- **Issue**: Different date formats from different APIs
- **Cursor API**: Sometimes returns timestamps as numbers (milliseconds)
- **Anthropic API**: ISO date strings
- **Resolution**: Robust date parsing with fallback logic

#### 4. **Cost-Usage Attribution Misalignment**
- **Issue**: Cost data lacks API key granularity (org-level only)
- **Impact**: Estimated cost allocation vs. precise attribution
- **Workaround**: Proportional cost allocation based on usage volume

#### 5. **Cache Token Complexity**
- **Issue**: Multiple cache-related token types in Anthropic data
- **Types**: `cached_input_tokens`, `cache_read_input_tokens`, `uncached_input_tokens`
- **Challenge**: Understanding cost implications of each type
- **Business Impact**: Affects accurate cost-per-token calculations

#### 6. **Historical Data Gaps**
- **Issue**: Pipeline started January 2025, missing historical context
- **Impact**: Limited trend analysis capability
- **Mitigation**: Historical data backfill via API date range requests

### Data Quality Monitoring Framework

#### Automated Quality Checks:
1. **Completeness**: % of records with user attribution
2. **Accuracy**: Platform mapping validation
3. **Freshness**: Hours since last data update
4. **Consistency**: Cross-platform user validation
5. **Validity**: Schema compliance and business rule validation

#### Quality Thresholds:
- **Attribution Rate**: Target ≥ 95%, Alert < 85%
- **Data Freshness**: Target < 6 hours, Alert > 24 hours
- **Schema Compliance**: Target 100%, Alert < 98%

---

## API Integration Details

### Cursor Admin API
**Endpoint**: `https://api.cursor.com/teams/daily-usage-data`
**Authentication**: Bearer token
**Rate Limits**: Not documented, uses exponential backoff
**Data Granularity**: User-day level with session details

### Anthropic Admin API
**Usage Endpoint**: `https://api.anthropic.com/v1/organizations/usage_report/messages`
**Cost Endpoint**: `https://api.anthropic.com/v1/organizations/cost_report`
**Authentication**: x-api-key header
**Rate Limits**: Paginated responses, max 5 pages per request
**Data Granularity**: API key-day level with hourly breakdown

### Google Sheets Integration
**Purpose**: API key to user mapping maintenance
**Sheet Structure**:
- `api_key_id` | `user_email` | `platform` | `purpose` | `status`
**Update Frequency**: Manual updates with cached reads (1-hour TTL)
**Validation**: Automated schema and format validation

---

## Performance Optimization

### BigQuery Optimization Strategy

#### Partitioning Strategy:
- **Raw Tables**: Partitioned by `ingest_date` (daily)
- **Fact Tables**: Partitioned by `usage_date`/`cost_date` (daily)
- **Partition Pruning**: All queries require partition filter

#### Clustering Strategy:
- **Raw Tables**: Clustered by primary query patterns (user, platform, date)
- **Fact Tables**: Clustered by `platform`, `user_email`, `model`
- **Query Performance**: 80%+ queries benefit from clustering

#### View Optimization:
- **Materialized Views**: Not used (prefer fresh data)
- **Date Filtering**: All views include 6-12 month date filters
- **Aggregation Pushdown**: Pre-aggregated CTEs for complex calculations

### Query Performance Patterns:
```sql
-- Optimized query pattern
SELECT *
FROM fct_usage_daily
WHERE usage_date BETWEEN DATE_SUB(CURRENT_DATE(), INTERVAL 30 DAY)
                     AND CURRENT_DATE()  -- Partition pruning
  AND platform = 'cursor'                -- Clustering benefit
  AND user_email LIKE 'eng-%'           -- Clustering benefit
```

---

## Security & Compliance

### Data Security Measures

#### API Key Management:
- **Storage**: Google Secret Manager
- **Rotation**: Manual rotation with pipeline restart
- **Access Control**: IAM-based access with principle of least privilege
- **Audit Trail**: All API key usage logged

#### PII Handling:
- **User Emails**: Business necessity for attribution
- **Data Retention**: 12 months active + 7 years archive
- **Access Logging**: All data access logged to Cloud Audit Logs
- **Data Anonymization**: Email hashing available for analytics

#### Compliance Framework:
- **SOC 2 Type II**: Data processing controls
- **GDPR**: Data subject rights implementation
- **Data Lineage**: Complete lineage tracking via request_id
- **Incident Response**: Automated alerting + manual escalation

---

## Operational Metrics

### Pipeline SLAs

#### Data Freshness SLAs:
- **Raw Data**: < 6 hours from API source
- **Fact Tables**: < 2 hours from raw data ingestion
- **Business Views**: < 1 hour from fact table updates
- **Dashboard Updates**: < 30 minutes from view updates

#### Quality SLAs:
- **Attribution Coverage**: ≥ 95% of records attributed
- **Data Accuracy**: ≥ 99% schema compliance
- **Pipeline Success Rate**: ≥ 99.5% successful executions
- **Error Recovery**: < 4 hours mean time to recovery

### Monitoring & Alerting

#### Key Alerts:
1. **Pipeline Failure**: Immediate PagerDuty alert
2. **Data Quality Drop**: Attribution rate < 85%
3. **Data Staleness**: No new data > 12 hours
4. **Cost Anomaly**: Daily cost > 150% of 7-day average
5. **Usage Spike**: User sessions > 200% of baseline

#### Metrics Dashboard:
- **Pipeline Health**: Success rates, execution times
- **Data Quality**: Attribution rates, error counts
- **Business Metrics**: Cost trends, user adoption
- **System Performance**: Query performance, resource usage

---

## Future Roadmap

### Planned Enhancements

#### Short Term (Q2 2025):
1. **Real-time Streaming**: Kafka-based real-time ingestion
2. **Advanced Attribution**: ML-based user attribution
3. **Cost Optimization**: Automated cost anomaly detection
4. **Extended Platforms**: Copilot, ChatGPT integration

#### Medium Term (Q3-Q4 2025):
1. **Predictive Analytics**: Usage and cost forecasting
2. **Advanced ROI Models**: Project-level ROI tracking
3. **Team Productivity**: Collaborative metrics
4. **Automated Insights**: AI-generated business insights

#### Long Term (2026+):
1. **Multi-Cloud**: AWS, Azure AI platform support
2. **Advanced Analytics**: Custom AI models for insights
3. **Integration Hub**: Slack, Teams, Jira integrations
4. **Self-Service Analytics**: Business user query interface

---

## Appendix

### Platform Mapping Reference
```json
{
  "claude_code": ["wrkspc_01WtfAtqQsV3zBDs9RYpNZdR"],
  "claude_api": ["direct API usage"],
  "cursor": ["cursor.com platform"],
  "claude_web": ["claude.ai web interface"]
}
```

### Common Query Patterns
```sql
-- Monthly cost by platform
SELECT
  DATE_TRUNC(cost_date, MONTH) as month,
  platform,
  SUM(cost_usd) as total_cost
FROM fct_cost_daily
WHERE cost_date >= DATE_SUB(CURRENT_DATE(), INTERVAL 12 MONTH)
GROUP BY 1, 2
ORDER BY 1 DESC, 3 DESC;

-- User productivity ranking
SELECT
  user_email,
  SUM(lines_of_code_accepted) as productivity,
  AVG(acceptance_rate) as avg_acceptance_rate,
  SUM(cost_usd) as total_cost
FROM fct_usage_daily u
LEFT JOIN fct_cost_daily c USING (usage_date, user_email, platform)
WHERE usage_date >= DATE_SUB(CURRENT_DATE(), INTERVAL 30 DAY)
GROUP BY 1
ORDER BY 2 DESC;
```

### Troubleshooting Guide

#### Common Issues:
1. **Attribution Failures**: Check Google Sheets connectivity
2. **Pipeline Delays**: Verify API rate limits and quotas
3. **Cost Discrepancies**: Validate platform mapping logic
4. **Query Performance**: Ensure partition filters applied

#### Emergency Contacts:
- **Pipeline Issues**: Engineering On-Call
- **Data Quality**: Data Team Lead
- **Cost Anomalies**: Finance + Engineering
- **Security Incidents**: Security Team + Legal

---

**Document Maintained By**: Winston (Architect Agent)
**Last Updated**: 2025-09-27
**Next Review**: 2025-10-27
**Version Control**: Git repository with change tracking