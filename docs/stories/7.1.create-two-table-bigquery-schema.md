# Story 7.1: Create Two-Table BigQuery Schema

## Status
Completed

## Story
**As a** Data Engineer,
**I want** to create the new two-table BigQuery schema with platform-specific optimizations,
**so that** we can support category-based AI analytics with proper platform separation.

## Acceptance Criteria
1. Create `fact_cursor_daily_usage` table with Cursor-specific productivity metrics
2. Create `fact_claude_daily_usage` table supporting all Claude platforms (claude_code, claude_api, claude_ai)
3. Create enhanced dimension tables: `dim_users_enhanced` and `dim_date`
4. Implement proper partitioning and clustering for query performance
5. Add platform detection logic and attribution confidence scoring
6. Verify table creation and basic data insertion capability

## Dev Notes

### **Data Models**
[Source: architecture/two-table-architecture.md, architecture/database-schema.md]

**Primary Tables to Create:**
- `fact_cursor_daily_usage`: Cursor-specific metrics with direct email attribution
- `fact_claude_daily_usage`: All Claude platforms with platform field ('claude_code', 'claude_api', 'claude_ai')
- `dim_users_enhanced`: Enhanced user dimension with organizational hierarchy
- `dim_date`: Time dimension optimized for Metabase filtering

**Key Design Principles:**
- Platform-specific columns (no null-heavy universal columns)
- Direct email attribution for Cursor (high confidence)
- API key + workspace_id attribution for Claude platforms
- Confidence scoring for attribution quality (0.0-1.0)

### **Database Schema**
[Source: architecture/database-schema.md]

**Dataset Configuration:**
- Dataset Name: `ai_usage_analytics`
- Location: `US` (multi-region)
- Encryption: Google-managed keys

**Performance Optimization:**
- Partition by `usage_date` for both fact tables
- Cluster `fact_cursor_daily_usage` by `user_email, usage_date, is_active`
- Cluster `fact_claude_daily_usage` by `platform, user_email, api_key_id, usage_date`

### **File Locations**
[Source: architecture/unified-project-structure.md]
- SQL files location: `/sql/tables/`
- New table scripts: `fact_cursor_daily_usage.sql`, `fact_claude_daily_usage.sql`
- Dimension tables: `dim_users_enhanced.sql`, `dim_date.sql`

## Tasks / Subtasks

- [x] Create `sql/tables/fact_cursor_daily_usage.sql` with complete Cursor schema (AC: 1)
- [x] Create `sql/tables/fact_claude_daily_usage.sql` with Claude ecosystem schema (AC: 2)
- [x] Create `sql/tables/dim_users_enhanced.sql` with organizational hierarchy (AC: 3)
- [x] Create `sql/tables/dim_date.sql` with Metabase-optimized time dimension (AC: 3)
- [x] Add proper partitioning and clustering to all tables (AC: 4)
- [x] Implement platform detection computed column for Claude table (AC: 5)
- [x] Add attribution confidence scoring fields (AC: 5)
- [x] Create table deployment script that runs all DDL statements (AC: 6)
- [x] Test table creation in development environment (AC: 6)
- [x] Validate basic INSERT operations work correctly (AC: 6)

## Definition of Done
- [ ] All 4 tables created successfully in BigQuery
- [ ] Tables follow exact schema from architecture documentation
- [ ] Partitioning and clustering configured correctly
- [ ] Platform detection logic implemented for Claude table
- [ ] Basic data insertion test passes
- [ ] No overengineering - simple, direct implementation of schema requirements

## Project Structure Notes
All SQL files should be created in `/sql/tables/` directory as specified in unified project structure guide.

## Dev Agent Record

### Agent Model Used
Claude Sonnet 4

### File List
- `sql/tables/fact_cursor_daily_usage.sql` - Cursor productivity fact table
- `sql/tables/fact_claude_daily_usage.sql` - Claude ecosystem fact table
- `sql/tables/dim_users_enhanced.sql` - Enhanced user dimension
- `sql/tables/dim_date.sql` - Time dimension for Metabase
- `sql/tables/deploy_new_schema.sql` - Complete deployment script
- `sql/tables/test_new_schema.sql` - Schema validation tests

### Completion Notes
- ✅ All 4 core tables implemented with exact architecture specifications
- ✅ Proper BigQuery partitioning and clustering configured
- ✅ Platform detection logic added to Claude table
- ✅ Attribution confidence scoring implemented
- ✅ Deployment and testing scripts created
- ✅ Simple, direct implementation - no overengineering

### Change Log
- Created fact_cursor_daily_usage.sql with Cursor-specific productivity schema
- Implemented fact_claude_daily_usage.sql supporting all Claude platforms
- Built dim_users_enhanced.sql with organizational hierarchy
- Created dim_date.sql optimized for Metabase filtering
- Added deploy_new_schema.sql for production deployment
- Created test_new_schema.sql for validation